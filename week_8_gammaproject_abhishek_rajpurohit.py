# -*- coding: utf-8 -*-
"""week_9_gammaProject_Abhishek_Rajpurohit.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ii1akXZ6iBN3fHOcue83n8ISM-dzoT0d
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder,StandardScaler
from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
import xgboost as xgb
from sklearn.neighbors import KNeighborsClassifier
from imblearn.combine import SMOTEENN
from imblearn.over_sampling import SMOTE
from sklearn.metrics import accuracy_score,classification_report,roc_curve,roc_auc_score,silhouette_score
from sklearn.cluster import KMeans,AgglomerativeClustering,DBSCAN
from sklearn.mixture import GaussianMixture
from joblib import parallel_backend
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier,VotingClassifier
from mpl_toolkits.mplot3d import Axes3D
import pickle

df = pd.read_csv('C:/Users/xbhi0/OneDrive/Desktop/week_9_solution/magic04.data',names=['fLength','fWidth','fSize','fConc','fConc1','fAsym','fM3Long','fM3Trans','fAlpha','fDist','class'])

#df.head()

""" Attribute information:

    1.  fLength:  continuous  # major axis of ellipse [mm]
    2.  fWidth:   continuous  # minor axis of ellipse [mm]
    3.  fSize:    continuous  # 10-log of sum of content of all pixels [in #phot]
    4.  fConc:    continuous  # ratio of sum of two highest pixels over fSize  [ratio]
    5.  fConc1:   continuous  # ratio of highest pixel over fSize  [ratio]
    6.  fAsym:    continuous  # distance from highest pixel to center, projected onto major axis [mm]
    7.  fM3Long:  continuous  # 3rd root of third moment along major axis  [mm]
    8.  fM3Trans: continuous  # 3rd root of third moment along minor axis  [mm]
    9.  fAlpha:   continuous  # angle of major axis with vector to origin [deg]
   10.  fDist:    continuous  # distance from origin to center of ellipse [mm]
   11.  class:    g,h         # gamma (signal), hadron (background)
"""

#! pip install pandas-Profiling

#import pandas_profiling

# profile = df.profile_report(title='Pandas Profiling Report')
# profile.to_file(output_file='report.html')

# from google.colab import files
# files.download("report.html")

"""# Data Types"""

df.info()

lb = LabelEncoder()

def func_for_LabelEncoding(data):

    encoded_data = data.copy()

    for column in encoded_data.columns:
        if encoded_data[column].dtype == 'object':
            label_encoder = LabelEncoder()
            encoded_data[column] = label_encoder.fit_transform(encoded_data[column])

    return encoded_data

df = func_for_LabelEncoding(df)

#df.head()

"""# Data Statistics"""

df.describe()

df.isnull().sum()

df.shape

"""# EDA"""

#df.hist(figsize=(10,10),bins=20)

"""TWO PATTERNS DETECTED -> GAUSSIAN AND LEFT SKEWED GASSIAN."""

# sns.lineplot(df)
# plt.title("Line Plot of Complete Data")
# plt.show()

# sns.pairplot(data=df)
# plt.title("Pair Plot")
# plt.show()

"""Our Data features showcase a good distribution and relationship with each other."""

cor_matrix = df.corr()

# sns.heatmap(data=cor_matrix,annot=True,cmap='rainbow')
# plt.title("Heat Map of Correlation between Features")
# plt.show()

"""**Observation:**

* flength, fWidth, fSize show good corelation between each other, which is quite obvious.
* fConc and fConc1 also shows similar relationship.
"""







"""# Model Training"""

Q1 = np.percentile(df, 25)
Q3 = np.percentile(df, 75)

IQR = Q3 - Q1
lower_bound = Q1 - (1.5 * IQR)
upper_bound = Q3 + (1.5 * IQR)

data_without_outliers = df[(df >= lower_bound) & (df <= upper_bound)]

data_without_outliers.head()

print(data_without_outliers.shape)

"""Removing outliers in dataset wont help us with the classification as the data is about the features of high energy gamma particles and this features may have big differences in the vales.

We are dropping columns 'fAsym','fConc1','fM3Long' as they show very little to negative correlation to class.
"""

X = df.drop(columns=['class','fAsym','fConc1','fM3Long'],axis=1)
y = df['class']

sc = StandardScaler()
scaled_data = sc.fit_transform(X)
std_x = pd.DataFrame(scaled_data,columns=X.columns)

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)

sampler = SMOTE()
X_train_resampled, y_train_resampled = sampler.fit_resample(X_train, y_train)

y_train_resampled.value_counts()

results = []

lr = LogisticRegression(max_iter=5000)
lr.fit(X_train_resampled,y_train_resampled)
y_pred = lr.predict(X_test)
y_pred_probs = lr.predict_proba(X_test)[:, 1]
LogisticRegression_accuracy = lr.score(X_test,y_test)
print(LogisticRegression_accuracy)

""" The simple classification accuracy is not meaningful for this data, since classifying a background event as signal is worse than classifying a signal event as background. For comparison of different classifiers an ROC curve has to be used."""

fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)
lr_auc = roc_auc_score(y_test, y_pred_probs)

plt.plot(fpr, tpr, label='ROC Curve (AUC = {:.2f})'.format(lr_auc))
plt.plot([0, 1], [0, 1], linestyle='--', color='r', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend()
plt.show()

results.append(('Logistic_Regression',lr_auc))

"""We have much better auc score = 0.84

With the help of this roc_auc_curve we can observe that the model predicts True Positives better than False Positive. A model with higher TPR and lower FPR indicates better classification performance.

# CROSS VALIDATION WITH SVM, DECISION TREE, AND RANDOMFOREST.
"""

classifiers = [
    SVC(),
    DecisionTreeClassifier(),
    RandomForestClassifier(),
     xgb.XGBClassifier()
]

with parallel_backend('multiprocessing'):
  for classifier in classifiers:
      scores = cross_val_score(classifier, X_train_resampled, y_train_resampled, cv=6,scoring='roc_auc')
      results.append((classifier.__class__.__name__, scores.mean()))

results.sort(key=lambda x: x[1], reverse=True)

for name, score in results:
    print(f"{name}: {score}")

"""# ENSEMBLE LEARNING"""

clf1 = DecisionTreeClassifier()
clf2 = KNeighborsClassifier()
clf3 = xgb.XGBClassifier()
clf4 = RandomForestClassifier()

ensemble_model = VotingClassifier(estimators=[('dt', clf1), ('knn', clf2), ('xbg', clf3),('rfc',clf4)], voting='hard')

with parallel_backend('multiprocessing'):
  ensemble_model.fit(X_train_resampled, y_train_resampled)
  y_pred = ensemble_model.predict(X_test)

ensemble_learning = roc_auc_score(y_test, y_pred)
results.append(('Ensemble Learning',ensemble_learning))
print("Validation Accuracy:", ensemble_learning)

"""# MODEL FINE TUNING"""

clf = RandomForestClassifier()

param_grid = {
    'n_estimators': [80, 100, 120],
    'max_depth': [5, 10, None],
    'min_samples_split': [2, 5, 10],
}

with parallel_backend('multiprocessing'):

    grid_search = GridSearchCV(clf, param_grid, cv=5)
    grid_search.fit(X, y)

best_params = grid_search.best_params_
best_clf = RandomForestClassifier(**best_params)
best_clf.fit(X_train, y_train)
y_pred = best_clf.predict(X_test)

fine_tune_rf_accuracy = roc_auc_score(y_test, y_pred)
results.append(('Fine tune Random Forest',fine_tune_rf_accuracy))
print("Validation Accuracy:", fine_tune_rf_accuracy)

"""# **CLUSTERING**

# KMEANS
"""

clustering_score = []

X1 = X.values
k=2
kmeans = KMeans(n_clusters=k)

kmeans.fit(X1)

kmeans_labels = kmeans.labels_

centroids = kmeans.cluster_centers_

plt.scatter(X1[:, 0], X1[:, 1], c=kmeans_labels)
plt.scatter(centroids[:, 0], centroids[:, 1], marker='x', color='red')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.title('K-means Clustering in 2D')
plt.show()

"""The distance between the centroids shows that the clusters have some differences and when viewed in a higher dimension will make more meaningful observations.

# 3D view of the cluster
"""

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter(X1[:, 0], X1[:, 1], X1[:, 2], c=kmeans_labels)
ax.scatter(centroids[:, 0], centroids[:, 1], centroids[:, 2], marker='x', color='red')
ax.set_xlabel('Feature 1')
ax.set_ylabel('Feature 2')
ax.set_zlabel('Feature 3')
ax.set_title('K-means Clustering in 3D')
plt.show()

kmeans_score = silhouette_score(X1, kmeans_labels)
clustering_score.append(('KMeans Clustering score',kmeans_score))
print("Silhouette Score for Kmeans:", kmeans_score)

"""The Silhouette Score ranges from -1 to 1, where higher values indicate better-defined clusters. Values close to 0 indicate overlapping clusters, and negative values suggest that samples have been assigned to incorrect clusters.

# DBSCAN
"""

dbscan = DBSCAN(eps=0.3, min_samples=5)

dbscan.fit(X1)
DBSCAN_labels = dbscan.labels_
unique_labels = np.unique(DBSCAN_labels)

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')

for label in unique_labels:
    if label == -1:
        color = 'k'
    else:
        color = np.random.rand(3,)

    cluster_points = X1[DBSCAN_labels == label]
    ax.scatter(cluster_points[:, 0], cluster_points[:, 1], cluster_points[:, 2], c=color, label=f'Cluster {label}')

ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z')
ax.set_title('DBSCAN Clustering')
ax.legend()
plt.show()

"""# GAUSSIAN MIXTURE MODEL CLUSTERING"""

gmm = GaussianMixture(n_components=2)

gmm.fit(X1)
gmm_labels = gmm.predict(X1)

unique_labels = np.unique(gmm_labels)

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')

for label in unique_labels:

    cluster_points = X1[gmm_labels == label]
    ax.scatter(cluster_points[:, 0], cluster_points[:, 1], cluster_points[:, 2], label=f'Cluster {label}')

ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z')
ax.set_title('Gaussian Mixture Model Clustering plot in 3D')
ax.legend()
plt.show()

means = gmm.means_

plt.scatter(X1[:, 0], X1[:, 1], c=gmm_labels, cmap='viridis')
plt.scatter(means[:, 0], means[:, 1], marker='x', color='red', s=100, label='Cluster Centers')
plt.xlabel('X')
plt.ylabel('Y')
plt.title('Gaussian Mixture Model Clustering plot in 2D')
plt.legend()
plt.show()

gmm_score = silhouette_score(X1, gmm_labels)
clustering_score.append(('GMM Clustering score',gmm_score))
print("Silhouette Score for GMM Clustering:", gmm_score)

"""# Agglomerative Clustering"""

agg_clustering = AgglomerativeClustering(n_clusters=2)
agg_clustering.fit(X1)
agg_labels = agg_clustering.labels_

plt.scatter(X1[:, 0], X1[:, 1], c=agg_labels, cmap='viridis')
plt.xlabel('X')
plt.ylabel('Y')
plt.title('Agglomerative Clustering')
plt.show()

agg_score = silhouette_score(X1, agg_labels)
clustering_score.append(('Agglomerative Clustering score',agg_score))
print("Silhouette Score for Agglomerative Clustering:", agg_score)

print(results)
print(clustering_score)

best_result_for_classification = max(results,key = lambda x : x[1])
print(best_result_for_classification)

best_result_for_clustering = max(clustering_score,key = lambda x : x[1])
print(best_result_for_clustering)

model1 = RandomForestClassifier()

model2 = kmeans

with open('model1.pkl', 'wb') as f:
    pickle.dump(model1, f)

with open('model2.pkl', 'wb') as f:
    pickle.dump(model2, f)

random_row = X.sample(n=1)
print(random_row)
data_without_feature_names = random_row.values

with open('model1.pkl', 'rb') as f:
    model1 = pickle.load(f)

with open('model2.pkl', 'rb') as f:
    model2 = pickle.load(f)

model1.fit(X_train,y_train)
classification_predictions = model1.predict(random_row)

classification_predictions

clusttering_prediction = model2.predict(data_without_feature_names)
clusttering_prediction

